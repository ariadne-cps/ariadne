/***************************************************************************
 *            algebraic_equations.dox
 *
 *  Copyright  2009  Pieter Collins
 *
 ****************************************************************************/

/*
 *  This program is free software; you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation; either version 2 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU Library General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program; if not, write to the Free Software
 *  Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
 */


/*!

\file algebraic_equations.dox
\brief Documentation on nonlinear algebraic equations


\page algebraic_equations_page Algebraic Equations

This page describes methods for the rigorous numerical solution of algebraic equations.
For details on how this is implemented in %Ariadne, see the \ref AlgebraicEquationSubModule documentation

Consider the system of nonlinear algebraic equations
\f[ f(x) = 0; \quad x\in D \f]
where \f$f:\R^n\rightarrow \R^n\f$ and \f$D\f$ is a compact box in \f$\R^n\f$.


\section interval_newton The Interval Newton Method

The interval Newton method is a direct intervalisation of the standard Newton method. Suppose \f$[x]\f$ is a box and \f$x\in[x]\f$.
Suppose further that there is a zero of \f$f\f$ at \f$x^*\in[x]\f$. Then by Taylor's theorem we have
\f[ 0 = f_i(x^*) = f_i(x) + Df_i(\xi_i) (x^*-x)  \f]
for some \f$\xi\in[x]\f$. Denoting the matrix formed by the gradients of \f$Df_i(\xi_i)\f$ by \f$Df(\xi)\f$ (note that this is <em>not</em> \f$Df\f$ evaluated at a single point \f$\xi\f$, we obtain
\f[ 0 = f(x^*) = f(x) + Df(\xi) (x^*-x)  \f]
and by rearranging,
\f[ x^* = x - Df(\xi)^{-1} f(x) . \f]
The interval Newton method is given by the contraction algorithm
\f[ \boxed{ [x_{n+1}] = [x_n] \cap \bigl( x_n - Df[x_n]^{-1} f(x_n) \bigr) } \f]
where \f$x_n\in[x_n]\f$ and \f$Df[x]\f$ is the interval matrix of all partial derivatives \f$ \partial f_i/\partial x_j[x]\f$.

\section krawczyk The Krawczyk  method

The main disadvantage of the interval Newton method is the need to invert the interval matrix \f$Df[x]\f$ which can be very wide.
The Krawczyk method is a modification of the interval Newton method which avoids this difficulty.

Let \f$x\in[x]\f$ and \f$J\f$ be any matrix. Then from the equation,
\f[ 0 = f(x) + Df(\xi) (x^*-x)  \f]
we multiply through by \f$ -J \f$ to obtain
\f[ 0 = -Jf(x) - JDf(\xi)(x^*-x)  \f]
Now add \f$(x^*-x)\f$ to both sides to obtain
\f[ x^*-x = -Jf(x) + (I - JDf(\xi)) (x^*-x)  \f]
and rearrange to obtain
\f[ x^* = x -Jf(x) + (I - JDf(\xi)) (x^*-x) . \f]
The Krawczyk method is given by the contraction algorithm
\f[ \boxed{ [x_{n+1}] = [x_n] \cap \bigl( x_n -J_nf(x_n) + (I - J_nDf[x_n]) ([x_n]-x]) \bigr) } \f]
Typically, we take either
\f[ \boxed{ J = \mathrm{mid}(Df[x])^{-1} \text{ or } J=Df(x)^{-1} } \f]

\section modified_krawczyk The Modified Krawczyk  Method

The main disadvantage of the Krawczyk method is the need to compute the matrix \f$I-JDf[x_n]\f$ explicitly, since otherwise the interval errors are too large. This is especially undesirable if \f$Df\f$ is sparse, since then typically \f$J\f$ will not be sparse, and while \f$JDf[x_n]\f$ will typically be close to \f$I\f$, the off-diagonal elements are significant. However, we can avoid losing the structure of \f$Df\f$ by the following modification.

Let \f$K\f$ be any matrix. Then from the equation
\f[ 0 = f(x) + Df(\xi) (x^*-x)  \f]
we negate the left-hand side and add \f$K(x^*-x)\f$ to both sides to obtain
\f[ K(x^*-x) = -f(x) + (K-Df(\xi)) (x^*-x)  \f]
Hence
\f[ x^* = x - K^{-1} \bigl( f(x) + (Df(\xi)-K) (x^*-x) \bigr) \f]
This gives a modified contraction algorithm
\f[ [x_{n+1}] = x_n - [K_n^{-1}] \bigl( f(x_n) + (Df[x_n]-K_n) ([x_n]-x_n) \bigr) \f]
Typically, we take \f$K=\mid(Df[x])\f$ so that \f$Df[x_n]-K_n\f$ is the matrix \f$\mathrm{rad}(Df[x_n])\f$.
Note that we need to take an interval solver for finding \f$K^{-1}\f$, since the method is only valid if \f$[K^{-1}]\f$ contains the exact inverse of \f$K\f$.

In many cases, we have a factorisation \f$K=PQR\f$ where \f$P^{-1}\f$ and \f$R^{-1}\f$ are sparse matrices which can be easily and exactly computed, and \f$Q\f$ is block-diagonal. We can then write \f$[Q]=[P^{-1}KR^{-1}]\f$ where the inverses are exact and the product is computed with interval arithmetic. Then \f$K^{-1} \in R^{-1} [Q]^{-1} P^{-1} = [K^{-1}]\f$, so the equation \f$K[x]=[r]\f$ can be solved easily.

As an example, in using the modified Krawczyk method to solve the Karush-Kuhn-Tucker conditions for nonlinear optimisation, we have to invert the matrix
\f[ \left(\begin{matrix} Z&0&X\\-A&H&0\\0&A^T&I\\ \end{matrix}\right) \f]
which factorises
\f[
    \left(\begin{matrix} Z&0&X\\-A&H&0\\0&A^T&I\\ \end{matrix}\right)
        =
    \left(\begin{matrix} Z&0&0 \\ 0&I&0 \\ 0&0&I \end{matrix}\right)
    \left(\begin{matrix} I&0&0 \\ -A&I&AZ^{-1}X \\ 0&0&I \end{matrix}\right)
    \left(\begin{matrix} I&0&0 \\ 0&H-AZ^{-1}XA^T&0 \\ 0&0&I \end{matrix}\right)
    \left(\begin{matrix} I&0&0 \\ 0&I&0 \\ 0&A^T&I \end{matrix}\right)
    \left(\begin{matrix} I&0&Z^{-1}X \\ 0&I&0 \\ 0&0&I \end{matrix}\right)
\f]
To compute the full interval inverse, we only need to invert the matrix \f$[H-AZ^{-1}XA^T]\f$, which is small and dense.

\section hotstarting_algebraic_equations Hotstarting Validated Algebraic Equation Solvers

A validated algebraic equation solver requires an initial box containing the solution.
We often have a candidate approximate solution \f$\tilde{x}\f$, and wish to prove the existence of a solution near \f$\tilde{x}\f$.
A precise definition of "near" is as follows:
<center><em>A solution \f$x^*\f$ of \f$f(x)=0\f$ is near \f$\tilde{x}\f$ if \f$\langle Df(\langle \tilde{x},x^*\rangle)\rangle\f$ is invertible.</em></center>
Here, \f$\langle \cdot \rangle\f$ denotes the convex hull.
We conjecture that there is at most one solution near any starting point.
A sufficient condition, which may be easier to check, is invertibility of \f$[Df([\tilde{x},x^*\rangle])]\f$, i.e. the interval hull of the Jacobians over the interval hull consists of invertible matrices.

An algorithm for computing a solution given a hotstart is to compute interval Newton iterates.
Whenever an iterate \f$[\hat{x}]\f$ is disjoint from \f$[x]\f$ in the \f$i\f$<sup>th</sup> component, we take \f$\mathrm{hull}([\hat{x}_i],\mathrm{mid}([x_i]))\f$ as the new component.


\section underdetermined_algebraic_equations Solving Underdetermined Algebraic Equations

If \f$ f:\R^n\fto\R^m \f$ with \f$ m < n \f$, then the system of equations \f$f(x)=0\f$ is underdetermined. A Newton-like step can be taken as
\f[ x_{n+1} = x_n - A^T (AA^T)^{-1} f(x_n) \text{ where } A=Df(x_n) . \f]





*/
